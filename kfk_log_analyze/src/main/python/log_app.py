# -*- coding: utf-8 -*-# @File  : log_app.py# @Author: Cleland# @Date  : 2019/4/26# @Desc  :from pyspark.sql import SparkSessiondef main():    spark = SparkSession.builder \        .appName('log_app') \        .master('yarn') \        .config('spark.driver.memory', '1g') \        .config('spark.executor.instances', '2') \        .config('spark.executor.core', '2') \        .config('spark.executor.memory', '1g') \        .getOrCreate()    df = spark.read.csv(path='hdfs://header:8020/data/input/access.log', sep='\t', header=False)    df = df.withColumnRenamed('_c0', 'time_stamp')    df = df.withColumnRenamed('_c1', 'device_id')    df = df.withColumnRenamed('_c2', 'up_traffic')    df = df.withColumnRenamed('_c3', 'down_traffic')    df.createOrReplaceTempView("log")    sql_statement = '''    SELECT        device_id        ,time_stamp        ,up_traffic        ,down_traffic    FROM (        SELECT            device_id            ,MIN(time_stamp) as time_stamp            ,SUM(up_traffic) as up_traffic            ,SUM(down_traffic) as down_traffic        FROM access_log        GROUP BY device_id    ) t    ORDER BY up_traffic, down_traffic, time_stamp DESC    LIMIT 10    '''    df = spark.sql(sql_statement)    df.show(10)if __name__ == '__main__':    main()